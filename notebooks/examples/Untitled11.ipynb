{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.insert(0, '../../')\n",
    "from definitions import *\n",
    "from src.data.dataset import TimeSeriesDataset\n",
    "import torch\n",
    "from src.data import dicts\n",
    "from src.features.signatures.compute import RollingSignature\n",
    "from src.features.rolling import RollingStatistic\n",
    "from src.data.functions import torch_ffill\n",
    "from src.features.derived_features import shock_index, partial_sofa, bun_cr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "dataset = TimeSeriesDataset().load(DATA_DIR + '/raw/data.tsd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6273, 336, 41])"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function RollingStatistic.transform at 0x0000024483532950> \n",
      "  996.01 ms\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# First get counts of the laboratory values\n",
    "count_variables = dicts.feature_types['laboratory'] + ['Temp']\n",
    "counts = RollingStatistic(statistic='count', window_length=8).transform(dataset[count_variables])\n",
    "dataset.add_features(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply a forward fill\n",
    "dataset.data = torch_ffill(dataset.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add on some additional features\n",
    "dataset['ShockIndex'] = shock_index(dataset)\n",
    "dataset['PartialSOFA'] = partial_sofa(dataset)\n",
    "dataset['BUN/CR'] = bun_cr(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function RollingStatistic.transform at 0x0000024483532950> \n",
      "  2610.22 ms\n"
     ]
    }
   ],
   "source": [
    "# Now moments\n",
    "changing_vars = dicts.feature_types['vitals']\n",
    "dataset.add_features(RollingStatistic(statistic='moments', window_length=7).transform(dataset[changing_vars]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function RollingStatistic.transform at 0x0000024483532950> \n",
      "  355.46 ms\n",
      "<function RollingStatistic.transform at 0x0000024483532950> \n",
      "  367.46 ms\n"
     ]
    }
   ],
   "source": [
    "# Now generate some rolling window features\n",
    "max_vals = RollingStatistic(statistic='max', window_length=6).transform(dataset[dicts.feature_types['vitals']])\n",
    "min_vals = RollingStatistic(statistic='min', window_length=6).transform(dataset[dicts.feature_types['vitals']])\n",
    "dataset.add_features(torch.cat((max_vals, min_vals), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function RollingSignature.transform at 0x00000244835322F0> \n",
      "  1031.78 ms\n",
      "<function RollingSignature.transform at 0x00000244835322F0> \n",
      "  830.37 ms\n",
      "<function RollingSignature.transform at 0x00000244835322F0> \n",
      "  837.96 ms\n",
      "<function RollingSignature.transform at 0x00000244835322F0> \n",
      "  901.65 ms\n",
      "<function RollingSignature.transform at 0x00000244835322F0> \n",
      "  1018.18 ms\n"
     ]
    }
   ],
   "source": [
    "# Now some rolling signatures\n",
    "roller = RollingSignature(window=7, depth=3, aug_list=['leadlag'], logsig=True)\n",
    "for vbl in ['BUN/CR', 'PartialSOFA', 'MAP', 'HR', 'SBP']:\n",
    "    signatures = roller.transform(dataset[vbl])\n",
    "    dataset.add_features(signatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract machine learning data\n",
    "data = dataset.to_ml()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = load_pickle(DATA_DIR + '/processed/labels/utility_scores.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[121669:]\n",
    "y = labels[121669:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup cv\n",
    "from sklearn.model_selection import cross_val_predict, StratifiedKFold, KFold\n",
    "#cv, cv_id = stratified_kfold_cv(X, y, n_splits=5, seed=5)\n",
    "# Choose cross val method\n",
    "#cv = list(StratifiedKFold(n_splits=5,random_state=1, shuffle=True).split(X, y))\n",
    "# Choose cross val method\n",
    "cv = list(KFold(5).split(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncv = []\\nfor i, fold in enumerate(list(id_cv)):\\n    train_idxs = [id_idxs[i] for i in fold[0]]\\n    test_idxs = [id_idxs[i] for i in fold[1]]\\n\\n    if not return_as_list:\\n        train_idxs = np.concatenate([id_idxs[i] for i in fold[0]])\\n        test_idxs = np.concatenate([id_idxs[i] for i in fold[1]])\\n\\n    cv.append([train_idxs, test_idxs])\\n'"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "cv = []\n",
    "for i, fold in enumerate(list(id_cv)):\n",
    "    train_idxs = [id_idxs[i] for i in fold[0]]\n",
    "    test_idxs = [id_idxs[i] for i in fold[1]]\n",
    "\n",
    "    if not return_as_list:\n",
    "        train_idxs = np.concatenate([id_idxs[i] for i in fold[0]])\n",
    "        test_idxs = np.concatenate([id_idxs[i] for i in fold[1]])\n",
    "\n",
    "    cv.append([train_idxs, test_idxs])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n"
     ]
    }
   ],
   "source": [
    "# Regressor\n",
    "from lightgbm import LGBMRegressor\n",
    "print('Training model...')\n",
    "#clf = LGBMRegressor().set_params(**lgbm_params)\n",
    "clf = LGBMRegressor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "              importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
       "              random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent='warn',\n",
       "              subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Training...\")\n",
    "clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = load_pickle(DATA_DIR + '/processed/labels/full_scores.pickle').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120492"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scores[121669:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresholding...\n",
      "Average: 0.268\n"
     ]
    }
   ],
   "source": [
    "from src.model.optimizer import CVThresholdOptimizer\n",
    "import numpy as np\n",
    "predictions = cross_val_predict(clf, X, y, cv=cv, n_jobs=-1)\n",
    "# Evaluation\n",
    "print('Thresholding...')\n",
    "score = CVThresholdOptimizer(y, predictions, scores= scores[121669:]).optimize(cv, parallel=True)\n",
    "\n",
    "print('Average: {:.3f}'.format(np.mean(score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.043\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "MSE = mean_squared_error (y, predictions)\n",
    "print('Train loss: {:.3f}'.format(MSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120492"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.  , -0.05, -0.05],\n",
       "       [ 0.  , -0.05, -0.05],\n",
       "       [ 0.  , -0.05, -0.05],\n",
       "       ...,\n",
       "       [ 0.  , -0.05, -0.05],\n",
       "       [ 0.  , -0.05, -0.05],\n",
       "       [ 0.  , -0.05, -0.05]])"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[121669:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scores[121669:])==len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model.optimizer import optimize_utility_threshold, compute_utility_from_indexes\n",
    "predictions = torch.from_numpy(predictions)\n",
    "tfm_np = lambda x: x.cpu().numpy()\n",
    "predictions = tfm_np(predictions)\n",
    "len(predictions)\n",
    "\n",
    "thresh = optimize_utility_threshold(predictions, scores= scores[121669:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train utility score: 0.282\n"
     ]
    }
   ],
   "source": [
    "train_utility = compute_utility_from_indexes(predictions, thresh, scores = scores[121669:])\n",
    "print('Train utility score: {:.3f}'.format(train_utility))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_y  = labels[:120491]\n",
    "predicted_y = clf.predict(data[:120491])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.100\n"
     ]
    }
   ],
   "source": [
    "MSE = mean_squared_error (expected_y, predicted_y)\n",
    "print('Test loss: {:.3f}'.format(MSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions1 = torch.from_numpy(predicted_y)\n",
    "tfm_np = lambda x: x.cpu().numpy()\n",
    "predictions1 = tfm_np(predictions1)\n",
    "thresh = optimize_utility_threshold(predictions, scores= scores[:120492])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test utility score: 0.186\n"
     ]
    }
   ],
   "source": [
    "train_utility = compute_utility_from_indexes(predictions1, thresh, scores = scores[:120491])\n",
    "print('Test utility score: {:.3f}'.format(train_utility))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
